import sys
import re

import requests
from bs4 import BeautifulSoup


TO_CRAWL = []
CRAWLED = set()
EMAILS = []
PHONES = []


def get_links(html):
    links = []
    try:
        soup = BeautifulSoup(html, "html.parser")
        tags_a = soup.find_all("a", href=True)
        
        for tag in tags_a:
            link = tag["href"]
            if link.startswith('http'):
                links.append(link)
        
        return links
        
    except: pass


def get_emails(html):
    emails = re.findall(r"\w[\w\.]+\w@\w[\w\.]+\w", html)
    return emails


def get_phones(html):
    phones = re.findall(r"\(?0?([1-9]{2,3})[ -\.\)]{0,2}?(9[ -\.]?)(\d{4})[ -\.]?(\d{4})", html)    
    return phones


def crawl():
    try:
        while True:
            if TO_CRAWL:
                url = TO_CRAWL.pop()
                response = requests.get(url)
                html = response.text
                links = get_links(html)

                if links:
                    for link in links:
                        if link not in CRAWLED and link not in TO_CRAWL:
                            TO_CRAWL.append(link)


                emails = get_emails(html)
                for email in emails:
                    if email not in EMAILS:
                        EMAILS.append(email)
                        print(f'    └\033[35m[e]\033[0;0;0m Email Found: \033[35m{email}\033[0;0;0m')
                
                
                phones = get_phones(html)
                for phone in phones:
                    str_phone = f"({phone[0]}){phone[1]}{phone[2]}-{phone[3]}"
                    if str_phone not in PHONES:
                        PHONES.append(str_phone)
                        print(f'    └\033[35m[p]\033[0;0;0m Phone Found: \033[34m{str_phone}\033[0;0;0m')

                print(f'\033[32m[+]\033[0;0;0m Crawling: \033[33m{url}\033[0;0;0m')
                CRAWLED.add(url)
            
            else:
                print("Done!")
                break
    
    except KeyboardInterrupt:
        print(f'\n\033[33m[i]\033[0;0;0m Program Finished by the user !')
        exit(0)
        
    except Exception as error: print(f'FATAL ERROR: {error}')


if __name__ == "__main__":
    art = """\033[35m            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣤⣺⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢿⠛⡿⣷⣿⣿⣿⣿⠉⣿⢻⣿⣿⢉⣿⡏⣿⡏⡇⠹⡟⡟⣟⠻⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢰⢻⣿⣿⣿⡿⣸⡿⣼⣿⣿⣾⣿⢧⣿⣿⣇⡤⣿⣷⣸⡄⣿⣿⣿⣿⣿⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣾⣿⣿⣿⣇⡟⠇⢈⡏⠿⢿⡇⠘⠿⢹⣇⣸⠏⠸⠇⠧⣼⣿⣿⣿⣿⣿⢿⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠸⣿⣿⣿⣿⡆⠾⢿⡿⣿⢿⠂⠀⠀⠀⠀⠟⡷⣶⡾⢿⡷⣿⣿⣿⣿⣿⣿⠎⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⢿⣿⣿⡘⡄⠘⠦⠭⠌⠀⠀⠀⠀⠀⠀⠳⣈⣁⡜⢀⣿⣿⡏⣿⣿⠞⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
\033[33mSP1D3R_W3EB\033[35m   ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠸⣿⣿⢷⣽⠀⠀⠀⠀⠀⠠⠀⠀⠀⠀⠀⠀⠀⠀⢼⠟⢿⣿⣿⠟⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
           ⢿⣭⣙⠛⠛⠒⠶⢤⣤⡀  \033[34mby\033[35m⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠀⣹⣧⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣠⣿⣿⣿⣼⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠈⢹⡿⢟⣉⣉⡀⠈⠙⠳⣦ \033[34mS1f_0\033[35m⢀⣀⣀⡀⠀⢠⣤⣄⡀⠀⡯⣿⣷⣦⣄⠀⠉⠒⠐⠁⠀⢀⡠⡾⠋⢿⣿⣿⡽⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⢸⣯⣐⣈⡟⠙⠀⠀⠀⠙⣧⠀⠀⠀⠀⠀⠘⠿⣭⣍⣉⡛⠛⠛⠛⠷⢿⣿⣿⣏⣉⣙⣶⣦⣀⡠⠴⠊⠉⠀⠿⣄⣤⣿⡿⢿⣾⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠈⠓⠶⠿⣤⣀⣀⡀⠀⠀⠈⢷⣄⠀⠀⠀⠀⠀⠀⠈⢹⡇⠀⠀⠀⠀⠀⠹⡀⠀⢠⣿⠋⠁⠀⣇⠀⠀⠀⠀⢀⡾⠃⠀⠀⠀⠀⠙⣧⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠉⢿⡀⠀⠀⠀⠻⣦⠀⠀⠀⠀⠀⠀⣼⡇⠀⠀⠀⠀⠀⠀⠹⣄⣿⠃⠢⠤⡀⠙⠀⣀⡤⢤⣾⣁⡆⢀⣀⡀⠀⠀⣿⣷⣦⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⢿⡄⠀⠀⠀⠙⢷⣄⠀⠀⢰⡞⠳⣶⡠⠤⠤⢤⣄⠀⠀⠙⣾⣷⠶⣖⣒⣀⣘⣂⣒⣾⣓⣒⣒⣒⠢⣬⣕⡉⢿⠻⣿⣷⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢿⣄⠀⠀⠀⠀⠙⢷⣴⠾⠻⡆⠈⢿⠄⠀⠀⠘⣆⠀⠀⠈⠻⣞⡋⠤⠤⠤⢤⠜⠃⠐⠋⠀⠀⠈⠉⠛⢿⣾⣵⣜⣿⣿⣇⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠹⣦⠀⠀⠀⠀⠈⠁⠀⠀⠙⢺⡀⢻⣆⠀⠀⢈⣦⠀⠀⠀⠙⢟⠻⢯⡍⣸⣤⣄⡀⠀⠀⠀⠀⢀⢀⡼⣟⣿⣿⣿⣿⣿⠄⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⣷⡄⠀⠀⠀⠀⠀⠀⣀⣼⣧⣄⣽⣲⣲⣻⣹⢦⠀⠀⠀⠀⠻⡟⠯⡅⠀⠉⠺⢕⣆⠀⠒⠁⡏⠀⣿⢹⣿⣿⣿⣿⡆⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣦⣀⣀⣤⡶⠟⠋⢹⣿⣿⢻⣿⡏⣿⣻⠀⠳⡀⠀⠀⠀⠙⠎⠑⠒⢺⡀⠀⠱⡵⢶⡊⠁⠀⣟⣿⠘⣟⠿⠇⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠉⠉⠁⠀⠀⠀⠘⢿⣿⡿⠼⠇⠙⣿⠀⣀⠹⡀⠀⠀⠀⠀⠀⠀⢠⡽⣻⣾⣿⣤⣿⣄⠀⣿⠛⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢿⡄⠛⠀⠙⣄⠀⠀⠀⢀⡼⠃⠀⠈⠙⠛⠿⣟⢿⢷⣿⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⣽⡀⢀⡀⠈⠳⠤⢖⡉⠀⠀⠀⠀⠀⠀⠀⠈⠿⠾⣏⣟⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠹⣳⡌⣩⠀⠀⠀⠘⠻⠀⠀⠀⠀⠀⠀⢀⡀⠤⠂⠉⣾⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢹⣧⠀⠀⠀⠀⠛⢿⣖⠒⠀⠀⠀⠀⠀⠀⠀⠀⠀⢷⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡾⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣘⣝⢄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠸⢷⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣀⣟⡯⢽⠛⠉⠉⢾⡦⣀⠀⠀⠀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢯⣇⠀⠀⠀⠀⡀⠀⠀⠈⢂⣤⡿⣋⡥⠔⠃⠀⠀⠀⠀⠈⠛⢵⡦⡀⠀⠀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⣿⡦⠀⠀⠀⢀⣀⣠⡶⣟⠟⠋⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⠿⡦⡀⠀⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⡿⡛⡛⣭⡿⠟⠓⡒⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢞⣄⠀⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣳⣿⣿⡛⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⢫⣧⠀
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢧⠃⠑⠈⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢫⣣
            ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣼⡟⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣠⣵⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀  
      \033[0;0;0m\n"""
    print(art)
    
    if len(sys.argv) >= 2:
        url = sys.argv[1]
        TO_CRAWL.append("http://" + url)
        crawl()
    
    else:
        print(f'\n\t\t\t\t\033[33m[i]\033[0;0;0m Usage: py \033[33mweb_crawler.py\033[0;0;0m < \033[33mdomain.com\033[0;0;0m >\n')
